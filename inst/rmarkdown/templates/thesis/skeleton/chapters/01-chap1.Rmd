# OBJECTIVE

\citet{messick1987validity} defines measurement validity as “an integrated evaluative judgment of the degree to which empirical evidence and theoretical rationales support the adequacy and appropriateness of inferences and actions based on test scores,” and notes that “validity is a matter of degree, not all or none (p. 3).” While there are multiple methods for evaluating and improving the validity of test scores, the goal of this study is to determine the effectiveness of using various cross-validation and bootstrap techniques with Rasch and 2PL models to determine which of multiple “short form” tests, whose items are drawn from a longer “full” test, best approximates the true criterion-related validity evidence. 

A standard method in practice for providing evidence of criterion validity is referred to as concurrent validity, which is performed by correlating the test in question with a concurrent measure that has validity evidence for the same (or a similar) use (Crocker and Algina, 1986). Examples are provided in Booth et al. (2003), Terwee et al. (2007), and Sallis and Saelens (2000). Another method in practice is predictive validity, implemented by using the scale score to predict some future behavior that the scale is purported to predict (Crocker and Algina, 1986). Examples are provided in Morisky et al. (2008), Newsome et al. (2000), and Lahey et al. (2015). 

There are many measurement instances in the social sciences in which a test score can be compared to an external categorical criterion in order to assess validity evidence of those test scores. For instance, as of 2012 25 states have high school exit exams that students are required to pass before receiving their high school diploma (McIntosh, 2012). These test scores must be directly related to an externally-defined standard for necessary student knowledge and ability in order for the exams to have meaning (Chudowsky et al., 2002), which may be categorical. As another example, Shapiro et al. (1999) used the revised Hopkins Verbal Learning Test (HVLT-R) as a predictor of whether or not an elderly adult would experience dementia. Many other examples can be found throughout the literature. 

Using cross-validation and bootstrapping techniques may allow for measurement practitioners to select a test form or set of test items that can best approximate the relationship between the test scores and the external categorical criterion. This study uses a simulation in which the true relationship between the latent trait being measured and the external categorical criterion is known. Then, multiple cross-validation and bootstrapping techniques are compared to determine which best selects a form that approximates the true degree of external validity evidence. Two factors relevant to practice were varied in the study to understand their relationships to the outcomes of the proposed methods. These include sample size and measurement model. 
